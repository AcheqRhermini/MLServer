# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: service.proto

from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor.FileDescriptor(
  name='service.proto',
  package='oink.inferenceserver',
  syntax='proto3',
  serialized_options=None,
  serialized_pb=b'\n\rservice.proto\x12\x14oink.inferenceserver\"\x13\n\x11ServerLiveRequest\"\"\n\x12ServerLiveResponse\x12\x0c\n\x04live\x18\x01 \x01(\x08\"\x14\n\x12ServerReadyRequest\"$\n\x13ServerReadyResponse\x12\r\n\x05ready\x18\x01 \x01(\x08\"2\n\x11ModelReadyRequest\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\"#\n\x12ModelReadyResponse\x12\r\n\x05ready\x18\x01 \x01(\x08\"\x17\n\x15ServerMetadataRequest\"K\n\x16ServerMetadataResponse\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\x12\x12\n\nextensions\x18\x03 \x03(\t\"5\n\x14ModelMetadataRequest\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\"\xa3\x02\n\x15ModelMetadataResponse\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x10\n\x08versions\x18\x02 \x03(\t\x12\x10\n\x08platform\x18\x03 \x01(\t\x12J\n\x06inputs\x18\x04 \x03(\x0b\x32:.oink.inferenceserver.ModelMetadataResponse.TensorMetadata\x12K\n\x07outputs\x18\x05 \x03(\x0b\x32:.oink.inferenceserver.ModelMetadataResponse.TensorMetadata\x1a?\n\x0eTensorMetadata\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x10\n\x08\x64\x61tatype\x18\x02 \x01(\t\x12\r\n\x05shape\x18\x03 \x03(\x03\"\xb5\x07\n\x11ModelInferRequest\x12\x12\n\nmodel_name\x18\x01 \x01(\t\x12\x15\n\rmodel_version\x18\x02 \x01(\t\x12\n\n\x02id\x18\x03 \x01(\t\x12K\n\nparameters\x18\x04 \x03(\x0b\x32\x37.oink.inferenceserver.ModelInferRequest.ParametersEntry\x12H\n\x06inputs\x18\x05 \x03(\x0b\x32\x38.oink.inferenceserver.ModelInferRequest.InferInputTensor\x12S\n\x07outputs\x18\x06 \x03(\x0b\x32\x42.oink.inferenceserver.ModelInferRequest.InferRequestedOutputTensor\x1a\xb5\x02\n\x10InferInputTensor\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x10\n\x08\x64\x61tatype\x18\x02 \x01(\t\x12\r\n\x05shape\x18\x03 \x03(\x03\x12\\\n\nparameters\x18\x04 \x03(\x0b\x32H.oink.inferenceserver.ModelInferRequest.InferInputTensor.ParametersEntry\x12;\n\x08\x63ontents\x18\x05 \x01(\x0b\x32).oink.inferenceserver.InferTensorContents\x1aW\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x33\n\x05value\x18\x02 \x01(\x0b\x32$.oink.inferenceserver.InferParameter:\x02\x38\x01\x1a\xeb\x01\n\x1aInferRequestedOutputTensor\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x66\n\nparameters\x18\x02 \x03(\x0b\x32R.oink.inferenceserver.ModelInferRequest.InferRequestedOutputTensor.ParametersEntry\x1aW\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x33\n\x05value\x18\x02 \x01(\x0b\x32$.oink.inferenceserver.InferParameter:\x02\x38\x01\x1aW\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x33\n\x05value\x18\x02 \x01(\x0b\x32$.oink.inferenceserver.InferParameter:\x02\x38\x01\"\xfa\x04\n\x12ModelInferResponse\x12\x12\n\nmodel_name\x18\x01 \x01(\t\x12\x15\n\rmodel_version\x18\x02 \x01(\t\x12\n\n\x02id\x18\x03 \x01(\t\x12L\n\nparameters\x18\x04 \x03(\x0b\x32\x38.oink.inferenceserver.ModelInferResponse.ParametersEntry\x12K\n\x07outputs\x18\x05 \x03(\x0b\x32:.oink.inferenceserver.ModelInferResponse.InferOutputTensor\x1a\xb8\x02\n\x11InferOutputTensor\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x10\n\x08\x64\x61tatype\x18\x02 \x01(\t\x12\r\n\x05shape\x18\x03 \x03(\x03\x12^\n\nparameters\x18\x04 \x03(\x0b\x32J.oink.inferenceserver.ModelInferResponse.InferOutputTensor.ParametersEntry\x12;\n\x08\x63ontents\x18\x05 \x01(\x0b\x32).oink.inferenceserver.InferTensorContents\x1aW\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x33\n\x05value\x18\x02 \x01(\x0b\x32$.oink.inferenceserver.InferParameter:\x02\x38\x01\x1aW\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x33\n\x05value\x18\x02 \x01(\x0b\x32$.oink.inferenceserver.InferParameter:\x02\x38\x01\"i\n\x0eInferParameter\x12\x14\n\nbool_param\x18\x01 \x01(\x08H\x00\x12\x15\n\x0bint64_param\x18\x02 \x01(\x03H\x00\x12\x16\n\x0cstring_param\x18\x03 \x01(\tH\x00\x42\x12\n\x10parameter_choice\"\xe6\x01\n\x13InferTensorContents\x12\x14\n\x0craw_contents\x18\x01 \x01(\x0c\x12\x15\n\rbool_contents\x18\x02 \x03(\x08\x12\x14\n\x0cint_contents\x18\x03 \x03(\x05\x12\x16\n\x0eint64_contents\x18\x04 \x03(\x03\x12\x15\n\ruint_contents\x18\x05 \x03(\r\x12\x17\n\x0fuint64_contents\x18\x06 \x03(\x04\x12\x15\n\rfp32_contents\x18\x07 \x03(\x02\x12\x15\n\rfp64_contents\x18\x08 \x03(\x01\x12\x16\n\x0e\x62ytes_contents\x18\t \x03(\x0c\x32\x80\x05\n\x14GRPCInferenceService\x12\x61\n\nServerLive\x12\'.oink.inferenceserver.ServerLiveRequest\x1a(.oink.inferenceserver.ServerLiveResponse\"\x00\x12\x64\n\x0bServerReady\x12(.oink.inferenceserver.ServerReadyRequest\x1a).oink.inferenceserver.ServerReadyResponse\"\x00\x12\x61\n\nModelReady\x12\'.oink.inferenceserver.ModelReadyRequest\x1a(.oink.inferenceserver.ModelReadyResponse\"\x00\x12m\n\x0eServerMetadata\x12+.oink.inferenceserver.ServerMetadataRequest\x1a,.oink.inferenceserver.ServerMetadataResponse\"\x00\x12j\n\rModelMetadata\x12*.oink.inferenceserver.ModelMetadataRequest\x1a+.oink.inferenceserver.ModelMetadataResponse\"\x00\x12\x61\n\nModelInfer\x12\'.oink.inferenceserver.ModelInferRequest\x1a(.oink.inferenceserver.ModelInferResponse\"\x00\x62\x06proto3'
)




_SERVERLIVEREQUEST = _descriptor.Descriptor(
  name='ServerLiveRequest',
  full_name='oink.inferenceserver.ServerLiveRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=39,
  serialized_end=58,
)


_SERVERLIVERESPONSE = _descriptor.Descriptor(
  name='ServerLiveResponse',
  full_name='oink.inferenceserver.ServerLiveResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='live', full_name='oink.inferenceserver.ServerLiveResponse.live', index=0,
      number=1, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=60,
  serialized_end=94,
)


_SERVERREADYREQUEST = _descriptor.Descriptor(
  name='ServerReadyRequest',
  full_name='oink.inferenceserver.ServerReadyRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=96,
  serialized_end=116,
)


_SERVERREADYRESPONSE = _descriptor.Descriptor(
  name='ServerReadyResponse',
  full_name='oink.inferenceserver.ServerReadyResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='ready', full_name='oink.inferenceserver.ServerReadyResponse.ready', index=0,
      number=1, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=118,
  serialized_end=154,
)


_MODELREADYREQUEST = _descriptor.Descriptor(
  name='ModelReadyRequest',
  full_name='oink.inferenceserver.ModelReadyRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='name', full_name='oink.inferenceserver.ModelReadyRequest.name', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='version', full_name='oink.inferenceserver.ModelReadyRequest.version', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=156,
  serialized_end=206,
)


_MODELREADYRESPONSE = _descriptor.Descriptor(
  name='ModelReadyResponse',
  full_name='oink.inferenceserver.ModelReadyResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='ready', full_name='oink.inferenceserver.ModelReadyResponse.ready', index=0,
      number=1, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=208,
  serialized_end=243,
)


_SERVERMETADATAREQUEST = _descriptor.Descriptor(
  name='ServerMetadataRequest',
  full_name='oink.inferenceserver.ServerMetadataRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=245,
  serialized_end=268,
)


_SERVERMETADATARESPONSE = _descriptor.Descriptor(
  name='ServerMetadataResponse',
  full_name='oink.inferenceserver.ServerMetadataResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='name', full_name='oink.inferenceserver.ServerMetadataResponse.name', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='version', full_name='oink.inferenceserver.ServerMetadataResponse.version', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='extensions', full_name='oink.inferenceserver.ServerMetadataResponse.extensions', index=2,
      number=3, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=270,
  serialized_end=345,
)


_MODELMETADATAREQUEST = _descriptor.Descriptor(
  name='ModelMetadataRequest',
  full_name='oink.inferenceserver.ModelMetadataRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='name', full_name='oink.inferenceserver.ModelMetadataRequest.name', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='version', full_name='oink.inferenceserver.ModelMetadataRequest.version', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=347,
  serialized_end=400,
)


_MODELMETADATARESPONSE_TENSORMETADATA = _descriptor.Descriptor(
  name='TensorMetadata',
  full_name='oink.inferenceserver.ModelMetadataResponse.TensorMetadata',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='name', full_name='oink.inferenceserver.ModelMetadataResponse.TensorMetadata.name', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='datatype', full_name='oink.inferenceserver.ModelMetadataResponse.TensorMetadata.datatype', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='shape', full_name='oink.inferenceserver.ModelMetadataResponse.TensorMetadata.shape', index=2,
      number=3, type=3, cpp_type=2, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=631,
  serialized_end=694,
)

_MODELMETADATARESPONSE = _descriptor.Descriptor(
  name='ModelMetadataResponse',
  full_name='oink.inferenceserver.ModelMetadataResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='name', full_name='oink.inferenceserver.ModelMetadataResponse.name', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='versions', full_name='oink.inferenceserver.ModelMetadataResponse.versions', index=1,
      number=2, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='platform', full_name='oink.inferenceserver.ModelMetadataResponse.platform', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='inputs', full_name='oink.inferenceserver.ModelMetadataResponse.inputs', index=3,
      number=4, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='outputs', full_name='oink.inferenceserver.ModelMetadataResponse.outputs', index=4,
      number=5, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[_MODELMETADATARESPONSE_TENSORMETADATA, ],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=403,
  serialized_end=694,
)


_MODELINFERREQUEST_INFERINPUTTENSOR_PARAMETERSENTRY = _descriptor.Descriptor(
  name='ParametersEntry',
  full_name='oink.inferenceserver.ModelInferRequest.InferInputTensor.ParametersEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='oink.inferenceserver.ModelInferRequest.InferInputTensor.ParametersEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='value', full_name='oink.inferenceserver.ModelInferRequest.InferInputTensor.ParametersEntry.value', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=b'8\001',
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1232,
  serialized_end=1319,
)

_MODELINFERREQUEST_INFERINPUTTENSOR = _descriptor.Descriptor(
  name='InferInputTensor',
  full_name='oink.inferenceserver.ModelInferRequest.InferInputTensor',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='name', full_name='oink.inferenceserver.ModelInferRequest.InferInputTensor.name', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='datatype', full_name='oink.inferenceserver.ModelInferRequest.InferInputTensor.datatype', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='shape', full_name='oink.inferenceserver.ModelInferRequest.InferInputTensor.shape', index=2,
      number=3, type=3, cpp_type=2, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='parameters', full_name='oink.inferenceserver.ModelInferRequest.InferInputTensor.parameters', index=3,
      number=4, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='contents', full_name='oink.inferenceserver.ModelInferRequest.InferInputTensor.contents', index=4,
      number=5, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[_MODELINFERREQUEST_INFERINPUTTENSOR_PARAMETERSENTRY, ],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1010,
  serialized_end=1319,
)

_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR_PARAMETERSENTRY = _descriptor.Descriptor(
  name='ParametersEntry',
  full_name='oink.inferenceserver.ModelInferRequest.InferRequestedOutputTensor.ParametersEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='oink.inferenceserver.ModelInferRequest.InferRequestedOutputTensor.ParametersEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='value', full_name='oink.inferenceserver.ModelInferRequest.InferRequestedOutputTensor.ParametersEntry.value', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=b'8\001',
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1232,
  serialized_end=1319,
)

_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR = _descriptor.Descriptor(
  name='InferRequestedOutputTensor',
  full_name='oink.inferenceserver.ModelInferRequest.InferRequestedOutputTensor',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='name', full_name='oink.inferenceserver.ModelInferRequest.InferRequestedOutputTensor.name', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='parameters', full_name='oink.inferenceserver.ModelInferRequest.InferRequestedOutputTensor.parameters', index=1,
      number=2, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR_PARAMETERSENTRY, ],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1322,
  serialized_end=1557,
)

_MODELINFERREQUEST_PARAMETERSENTRY = _descriptor.Descriptor(
  name='ParametersEntry',
  full_name='oink.inferenceserver.ModelInferRequest.ParametersEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='oink.inferenceserver.ModelInferRequest.ParametersEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='value', full_name='oink.inferenceserver.ModelInferRequest.ParametersEntry.value', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=b'8\001',
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1232,
  serialized_end=1319,
)

_MODELINFERREQUEST = _descriptor.Descriptor(
  name='ModelInferRequest',
  full_name='oink.inferenceserver.ModelInferRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='model_name', full_name='oink.inferenceserver.ModelInferRequest.model_name', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='model_version', full_name='oink.inferenceserver.ModelInferRequest.model_version', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='id', full_name='oink.inferenceserver.ModelInferRequest.id', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='parameters', full_name='oink.inferenceserver.ModelInferRequest.parameters', index=3,
      number=4, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='inputs', full_name='oink.inferenceserver.ModelInferRequest.inputs', index=4,
      number=5, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='outputs', full_name='oink.inferenceserver.ModelInferRequest.outputs', index=5,
      number=6, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[_MODELINFERREQUEST_INFERINPUTTENSOR, _MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR, _MODELINFERREQUEST_PARAMETERSENTRY, ],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=697,
  serialized_end=1646,
)


_MODELINFERRESPONSE_INFEROUTPUTTENSOR_PARAMETERSENTRY = _descriptor.Descriptor(
  name='ParametersEntry',
  full_name='oink.inferenceserver.ModelInferResponse.InferOutputTensor.ParametersEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='oink.inferenceserver.ModelInferResponse.InferOutputTensor.ParametersEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='value', full_name='oink.inferenceserver.ModelInferResponse.InferOutputTensor.ParametersEntry.value', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=b'8\001',
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1232,
  serialized_end=1319,
)

_MODELINFERRESPONSE_INFEROUTPUTTENSOR = _descriptor.Descriptor(
  name='InferOutputTensor',
  full_name='oink.inferenceserver.ModelInferResponse.InferOutputTensor',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='name', full_name='oink.inferenceserver.ModelInferResponse.InferOutputTensor.name', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='datatype', full_name='oink.inferenceserver.ModelInferResponse.InferOutputTensor.datatype', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='shape', full_name='oink.inferenceserver.ModelInferResponse.InferOutputTensor.shape', index=2,
      number=3, type=3, cpp_type=2, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='parameters', full_name='oink.inferenceserver.ModelInferResponse.InferOutputTensor.parameters', index=3,
      number=4, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='contents', full_name='oink.inferenceserver.ModelInferResponse.InferOutputTensor.contents', index=4,
      number=5, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[_MODELINFERRESPONSE_INFEROUTPUTTENSOR_PARAMETERSENTRY, ],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1882,
  serialized_end=2194,
)

_MODELINFERRESPONSE_PARAMETERSENTRY = _descriptor.Descriptor(
  name='ParametersEntry',
  full_name='oink.inferenceserver.ModelInferResponse.ParametersEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='oink.inferenceserver.ModelInferResponse.ParametersEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='value', full_name='oink.inferenceserver.ModelInferResponse.ParametersEntry.value', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=b'8\001',
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1232,
  serialized_end=1319,
)

_MODELINFERRESPONSE = _descriptor.Descriptor(
  name='ModelInferResponse',
  full_name='oink.inferenceserver.ModelInferResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='model_name', full_name='oink.inferenceserver.ModelInferResponse.model_name', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='model_version', full_name='oink.inferenceserver.ModelInferResponse.model_version', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='id', full_name='oink.inferenceserver.ModelInferResponse.id', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='parameters', full_name='oink.inferenceserver.ModelInferResponse.parameters', index=3,
      number=4, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='outputs', full_name='oink.inferenceserver.ModelInferResponse.outputs', index=4,
      number=5, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[_MODELINFERRESPONSE_INFEROUTPUTTENSOR, _MODELINFERRESPONSE_PARAMETERSENTRY, ],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1649,
  serialized_end=2283,
)


_INFERPARAMETER = _descriptor.Descriptor(
  name='InferParameter',
  full_name='oink.inferenceserver.InferParameter',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='bool_param', full_name='oink.inferenceserver.InferParameter.bool_param', index=0,
      number=1, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='int64_param', full_name='oink.inferenceserver.InferParameter.int64_param', index=1,
      number=2, type=3, cpp_type=2, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='string_param', full_name='oink.inferenceserver.InferParameter.string_param', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='parameter_choice', full_name='oink.inferenceserver.InferParameter.parameter_choice',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=2285,
  serialized_end=2390,
)


_INFERTENSORCONTENTS = _descriptor.Descriptor(
  name='InferTensorContents',
  full_name='oink.inferenceserver.InferTensorContents',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='raw_contents', full_name='oink.inferenceserver.InferTensorContents.raw_contents', index=0,
      number=1, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=b"",
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='bool_contents', full_name='oink.inferenceserver.InferTensorContents.bool_contents', index=1,
      number=2, type=8, cpp_type=7, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='int_contents', full_name='oink.inferenceserver.InferTensorContents.int_contents', index=2,
      number=3, type=5, cpp_type=1, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='int64_contents', full_name='oink.inferenceserver.InferTensorContents.int64_contents', index=3,
      number=4, type=3, cpp_type=2, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='uint_contents', full_name='oink.inferenceserver.InferTensorContents.uint_contents', index=4,
      number=5, type=13, cpp_type=3, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='uint64_contents', full_name='oink.inferenceserver.InferTensorContents.uint64_contents', index=5,
      number=6, type=4, cpp_type=4, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='fp32_contents', full_name='oink.inferenceserver.InferTensorContents.fp32_contents', index=6,
      number=7, type=2, cpp_type=6, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='fp64_contents', full_name='oink.inferenceserver.InferTensorContents.fp64_contents', index=7,
      number=8, type=1, cpp_type=5, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='bytes_contents', full_name='oink.inferenceserver.InferTensorContents.bytes_contents', index=8,
      number=9, type=12, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=2393,
  serialized_end=2623,
)

_MODELMETADATARESPONSE_TENSORMETADATA.containing_type = _MODELMETADATARESPONSE
_MODELMETADATARESPONSE.fields_by_name['inputs'].message_type = _MODELMETADATARESPONSE_TENSORMETADATA
_MODELMETADATARESPONSE.fields_by_name['outputs'].message_type = _MODELMETADATARESPONSE_TENSORMETADATA
_MODELINFERREQUEST_INFERINPUTTENSOR_PARAMETERSENTRY.fields_by_name['value'].message_type = _INFERPARAMETER
_MODELINFERREQUEST_INFERINPUTTENSOR_PARAMETERSENTRY.containing_type = _MODELINFERREQUEST_INFERINPUTTENSOR
_MODELINFERREQUEST_INFERINPUTTENSOR.fields_by_name['parameters'].message_type = _MODELINFERREQUEST_INFERINPUTTENSOR_PARAMETERSENTRY
_MODELINFERREQUEST_INFERINPUTTENSOR.fields_by_name['contents'].message_type = _INFERTENSORCONTENTS
_MODELINFERREQUEST_INFERINPUTTENSOR.containing_type = _MODELINFERREQUEST
_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR_PARAMETERSENTRY.fields_by_name['value'].message_type = _INFERPARAMETER
_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR_PARAMETERSENTRY.containing_type = _MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR
_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR.fields_by_name['parameters'].message_type = _MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR_PARAMETERSENTRY
_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR.containing_type = _MODELINFERREQUEST
_MODELINFERREQUEST_PARAMETERSENTRY.fields_by_name['value'].message_type = _INFERPARAMETER
_MODELINFERREQUEST_PARAMETERSENTRY.containing_type = _MODELINFERREQUEST
_MODELINFERREQUEST.fields_by_name['parameters'].message_type = _MODELINFERREQUEST_PARAMETERSENTRY
_MODELINFERREQUEST.fields_by_name['inputs'].message_type = _MODELINFERREQUEST_INFERINPUTTENSOR
_MODELINFERREQUEST.fields_by_name['outputs'].message_type = _MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR
_MODELINFERRESPONSE_INFEROUTPUTTENSOR_PARAMETERSENTRY.fields_by_name['value'].message_type = _INFERPARAMETER
_MODELINFERRESPONSE_INFEROUTPUTTENSOR_PARAMETERSENTRY.containing_type = _MODELINFERRESPONSE_INFEROUTPUTTENSOR
_MODELINFERRESPONSE_INFEROUTPUTTENSOR.fields_by_name['parameters'].message_type = _MODELINFERRESPONSE_INFEROUTPUTTENSOR_PARAMETERSENTRY
_MODELINFERRESPONSE_INFEROUTPUTTENSOR.fields_by_name['contents'].message_type = _INFERTENSORCONTENTS
_MODELINFERRESPONSE_INFEROUTPUTTENSOR.containing_type = _MODELINFERRESPONSE
_MODELINFERRESPONSE_PARAMETERSENTRY.fields_by_name['value'].message_type = _INFERPARAMETER
_MODELINFERRESPONSE_PARAMETERSENTRY.containing_type = _MODELINFERRESPONSE
_MODELINFERRESPONSE.fields_by_name['parameters'].message_type = _MODELINFERRESPONSE_PARAMETERSENTRY
_MODELINFERRESPONSE.fields_by_name['outputs'].message_type = _MODELINFERRESPONSE_INFEROUTPUTTENSOR
_INFERPARAMETER.oneofs_by_name['parameter_choice'].fields.append(
  _INFERPARAMETER.fields_by_name['bool_param'])
_INFERPARAMETER.fields_by_name['bool_param'].containing_oneof = _INFERPARAMETER.oneofs_by_name['parameter_choice']
_INFERPARAMETER.oneofs_by_name['parameter_choice'].fields.append(
  _INFERPARAMETER.fields_by_name['int64_param'])
_INFERPARAMETER.fields_by_name['int64_param'].containing_oneof = _INFERPARAMETER.oneofs_by_name['parameter_choice']
_INFERPARAMETER.oneofs_by_name['parameter_choice'].fields.append(
  _INFERPARAMETER.fields_by_name['string_param'])
_INFERPARAMETER.fields_by_name['string_param'].containing_oneof = _INFERPARAMETER.oneofs_by_name['parameter_choice']
DESCRIPTOR.message_types_by_name['ServerLiveRequest'] = _SERVERLIVEREQUEST
DESCRIPTOR.message_types_by_name['ServerLiveResponse'] = _SERVERLIVERESPONSE
DESCRIPTOR.message_types_by_name['ServerReadyRequest'] = _SERVERREADYREQUEST
DESCRIPTOR.message_types_by_name['ServerReadyResponse'] = _SERVERREADYRESPONSE
DESCRIPTOR.message_types_by_name['ModelReadyRequest'] = _MODELREADYREQUEST
DESCRIPTOR.message_types_by_name['ModelReadyResponse'] = _MODELREADYRESPONSE
DESCRIPTOR.message_types_by_name['ServerMetadataRequest'] = _SERVERMETADATAREQUEST
DESCRIPTOR.message_types_by_name['ServerMetadataResponse'] = _SERVERMETADATARESPONSE
DESCRIPTOR.message_types_by_name['ModelMetadataRequest'] = _MODELMETADATAREQUEST
DESCRIPTOR.message_types_by_name['ModelMetadataResponse'] = _MODELMETADATARESPONSE
DESCRIPTOR.message_types_by_name['ModelInferRequest'] = _MODELINFERREQUEST
DESCRIPTOR.message_types_by_name['ModelInferResponse'] = _MODELINFERRESPONSE
DESCRIPTOR.message_types_by_name['InferParameter'] = _INFERPARAMETER
DESCRIPTOR.message_types_by_name['InferTensorContents'] = _INFERTENSORCONTENTS
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

ServerLiveRequest = _reflection.GeneratedProtocolMessageType('ServerLiveRequest', (_message.Message,), {
  'DESCRIPTOR' : _SERVERLIVEREQUEST,
  '__module__' : 'service_pb2'
  # @@protoc_insertion_point(class_scope:oink.inferenceserver.ServerLiveRequest)
  })
_sym_db.RegisterMessage(ServerLiveRequest)

ServerLiveResponse = _reflection.GeneratedProtocolMessageType('ServerLiveResponse', (_message.Message,), {
  'DESCRIPTOR' : _SERVERLIVERESPONSE,
  '__module__' : 'service_pb2'
  # @@protoc_insertion_point(class_scope:oink.inferenceserver.ServerLiveResponse)
  })
_sym_db.RegisterMessage(ServerLiveResponse)

ServerReadyRequest = _reflection.GeneratedProtocolMessageType('ServerReadyRequest', (_message.Message,), {
  'DESCRIPTOR' : _SERVERREADYREQUEST,
  '__module__' : 'service_pb2'
  # @@protoc_insertion_point(class_scope:oink.inferenceserver.ServerReadyRequest)
  })
_sym_db.RegisterMessage(ServerReadyRequest)

ServerReadyResponse = _reflection.GeneratedProtocolMessageType('ServerReadyResponse', (_message.Message,), {
  'DESCRIPTOR' : _SERVERREADYRESPONSE,
  '__module__' : 'service_pb2'
  # @@protoc_insertion_point(class_scope:oink.inferenceserver.ServerReadyResponse)
  })
_sym_db.RegisterMessage(ServerReadyResponse)

ModelReadyRequest = _reflection.GeneratedProtocolMessageType('ModelReadyRequest', (_message.Message,), {
  'DESCRIPTOR' : _MODELREADYREQUEST,
  '__module__' : 'service_pb2'
  # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelReadyRequest)
  })
_sym_db.RegisterMessage(ModelReadyRequest)

ModelReadyResponse = _reflection.GeneratedProtocolMessageType('ModelReadyResponse', (_message.Message,), {
  'DESCRIPTOR' : _MODELREADYRESPONSE,
  '__module__' : 'service_pb2'
  # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelReadyResponse)
  })
_sym_db.RegisterMessage(ModelReadyResponse)

ServerMetadataRequest = _reflection.GeneratedProtocolMessageType('ServerMetadataRequest', (_message.Message,), {
  'DESCRIPTOR' : _SERVERMETADATAREQUEST,
  '__module__' : 'service_pb2'
  # @@protoc_insertion_point(class_scope:oink.inferenceserver.ServerMetadataRequest)
  })
_sym_db.RegisterMessage(ServerMetadataRequest)

ServerMetadataResponse = _reflection.GeneratedProtocolMessageType('ServerMetadataResponse', (_message.Message,), {
  'DESCRIPTOR' : _SERVERMETADATARESPONSE,
  '__module__' : 'service_pb2'
  # @@protoc_insertion_point(class_scope:oink.inferenceserver.ServerMetadataResponse)
  })
_sym_db.RegisterMessage(ServerMetadataResponse)

ModelMetadataRequest = _reflection.GeneratedProtocolMessageType('ModelMetadataRequest', (_message.Message,), {
  'DESCRIPTOR' : _MODELMETADATAREQUEST,
  '__module__' : 'service_pb2'
  # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelMetadataRequest)
  })
_sym_db.RegisterMessage(ModelMetadataRequest)

ModelMetadataResponse = _reflection.GeneratedProtocolMessageType('ModelMetadataResponse', (_message.Message,), {

  'TensorMetadata' : _reflection.GeneratedProtocolMessageType('TensorMetadata', (_message.Message,), {
    'DESCRIPTOR' : _MODELMETADATARESPONSE_TENSORMETADATA,
    '__module__' : 'service_pb2'
    # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelMetadataResponse.TensorMetadata)
    })
  ,
  'DESCRIPTOR' : _MODELMETADATARESPONSE,
  '__module__' : 'service_pb2'
  # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelMetadataResponse)
  })
_sym_db.RegisterMessage(ModelMetadataResponse)
_sym_db.RegisterMessage(ModelMetadataResponse.TensorMetadata)

ModelInferRequest = _reflection.GeneratedProtocolMessageType('ModelInferRequest', (_message.Message,), {

  'InferInputTensor' : _reflection.GeneratedProtocolMessageType('InferInputTensor', (_message.Message,), {

    'ParametersEntry' : _reflection.GeneratedProtocolMessageType('ParametersEntry', (_message.Message,), {
      'DESCRIPTOR' : _MODELINFERREQUEST_INFERINPUTTENSOR_PARAMETERSENTRY,
      '__module__' : 'service_pb2'
      # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelInferRequest.InferInputTensor.ParametersEntry)
      })
    ,
    'DESCRIPTOR' : _MODELINFERREQUEST_INFERINPUTTENSOR,
    '__module__' : 'service_pb2'
    # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelInferRequest.InferInputTensor)
    })
  ,

  'InferRequestedOutputTensor' : _reflection.GeneratedProtocolMessageType('InferRequestedOutputTensor', (_message.Message,), {

    'ParametersEntry' : _reflection.GeneratedProtocolMessageType('ParametersEntry', (_message.Message,), {
      'DESCRIPTOR' : _MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR_PARAMETERSENTRY,
      '__module__' : 'service_pb2'
      # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelInferRequest.InferRequestedOutputTensor.ParametersEntry)
      })
    ,
    'DESCRIPTOR' : _MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR,
    '__module__' : 'service_pb2'
    # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelInferRequest.InferRequestedOutputTensor)
    })
  ,

  'ParametersEntry' : _reflection.GeneratedProtocolMessageType('ParametersEntry', (_message.Message,), {
    'DESCRIPTOR' : _MODELINFERREQUEST_PARAMETERSENTRY,
    '__module__' : 'service_pb2'
    # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelInferRequest.ParametersEntry)
    })
  ,
  'DESCRIPTOR' : _MODELINFERREQUEST,
  '__module__' : 'service_pb2'
  # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelInferRequest)
  })
_sym_db.RegisterMessage(ModelInferRequest)
_sym_db.RegisterMessage(ModelInferRequest.InferInputTensor)
_sym_db.RegisterMessage(ModelInferRequest.InferInputTensor.ParametersEntry)
_sym_db.RegisterMessage(ModelInferRequest.InferRequestedOutputTensor)
_sym_db.RegisterMessage(ModelInferRequest.InferRequestedOutputTensor.ParametersEntry)
_sym_db.RegisterMessage(ModelInferRequest.ParametersEntry)

ModelInferResponse = _reflection.GeneratedProtocolMessageType('ModelInferResponse', (_message.Message,), {

  'InferOutputTensor' : _reflection.GeneratedProtocolMessageType('InferOutputTensor', (_message.Message,), {

    'ParametersEntry' : _reflection.GeneratedProtocolMessageType('ParametersEntry', (_message.Message,), {
      'DESCRIPTOR' : _MODELINFERRESPONSE_INFEROUTPUTTENSOR_PARAMETERSENTRY,
      '__module__' : 'service_pb2'
      # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelInferResponse.InferOutputTensor.ParametersEntry)
      })
    ,
    'DESCRIPTOR' : _MODELINFERRESPONSE_INFEROUTPUTTENSOR,
    '__module__' : 'service_pb2'
    # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelInferResponse.InferOutputTensor)
    })
  ,

  'ParametersEntry' : _reflection.GeneratedProtocolMessageType('ParametersEntry', (_message.Message,), {
    'DESCRIPTOR' : _MODELINFERRESPONSE_PARAMETERSENTRY,
    '__module__' : 'service_pb2'
    # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelInferResponse.ParametersEntry)
    })
  ,
  'DESCRIPTOR' : _MODELINFERRESPONSE,
  '__module__' : 'service_pb2'
  # @@protoc_insertion_point(class_scope:oink.inferenceserver.ModelInferResponse)
  })
_sym_db.RegisterMessage(ModelInferResponse)
_sym_db.RegisterMessage(ModelInferResponse.InferOutputTensor)
_sym_db.RegisterMessage(ModelInferResponse.InferOutputTensor.ParametersEntry)
_sym_db.RegisterMessage(ModelInferResponse.ParametersEntry)

InferParameter = _reflection.GeneratedProtocolMessageType('InferParameter', (_message.Message,), {
  'DESCRIPTOR' : _INFERPARAMETER,
  '__module__' : 'service_pb2'
  # @@protoc_insertion_point(class_scope:oink.inferenceserver.InferParameter)
  })
_sym_db.RegisterMessage(InferParameter)

InferTensorContents = _reflection.GeneratedProtocolMessageType('InferTensorContents', (_message.Message,), {
  'DESCRIPTOR' : _INFERTENSORCONTENTS,
  '__module__' : 'service_pb2'
  # @@protoc_insertion_point(class_scope:oink.inferenceserver.InferTensorContents)
  })
_sym_db.RegisterMessage(InferTensorContents)


_MODELINFERREQUEST_INFERINPUTTENSOR_PARAMETERSENTRY._options = None
_MODELINFERREQUEST_INFERREQUESTEDOUTPUTTENSOR_PARAMETERSENTRY._options = None
_MODELINFERREQUEST_PARAMETERSENTRY._options = None
_MODELINFERRESPONSE_INFEROUTPUTTENSOR_PARAMETERSENTRY._options = None
_MODELINFERRESPONSE_PARAMETERSENTRY._options = None

_GRPCINFERENCESERVICE = _descriptor.ServiceDescriptor(
  name='GRPCInferenceService',
  full_name='oink.inferenceserver.GRPCInferenceService',
  file=DESCRIPTOR,
  index=0,
  serialized_options=None,
  serialized_start=2626,
  serialized_end=3266,
  methods=[
  _descriptor.MethodDescriptor(
    name='ServerLive',
    full_name='oink.inferenceserver.GRPCInferenceService.ServerLive',
    index=0,
    containing_service=None,
    input_type=_SERVERLIVEREQUEST,
    output_type=_SERVERLIVERESPONSE,
    serialized_options=None,
  ),
  _descriptor.MethodDescriptor(
    name='ServerReady',
    full_name='oink.inferenceserver.GRPCInferenceService.ServerReady',
    index=1,
    containing_service=None,
    input_type=_SERVERREADYREQUEST,
    output_type=_SERVERREADYRESPONSE,
    serialized_options=None,
  ),
  _descriptor.MethodDescriptor(
    name='ModelReady',
    full_name='oink.inferenceserver.GRPCInferenceService.ModelReady',
    index=2,
    containing_service=None,
    input_type=_MODELREADYREQUEST,
    output_type=_MODELREADYRESPONSE,
    serialized_options=None,
  ),
  _descriptor.MethodDescriptor(
    name='ServerMetadata',
    full_name='oink.inferenceserver.GRPCInferenceService.ServerMetadata',
    index=3,
    containing_service=None,
    input_type=_SERVERMETADATAREQUEST,
    output_type=_SERVERMETADATARESPONSE,
    serialized_options=None,
  ),
  _descriptor.MethodDescriptor(
    name='ModelMetadata',
    full_name='oink.inferenceserver.GRPCInferenceService.ModelMetadata',
    index=4,
    containing_service=None,
    input_type=_MODELMETADATAREQUEST,
    output_type=_MODELMETADATARESPONSE,
    serialized_options=None,
  ),
  _descriptor.MethodDescriptor(
    name='ModelInfer',
    full_name='oink.inferenceserver.GRPCInferenceService.ModelInfer',
    index=5,
    containing_service=None,
    input_type=_MODELINFERREQUEST,
    output_type=_MODELINFERRESPONSE,
    serialized_options=None,
  ),
])
_sym_db.RegisterServiceDescriptor(_GRPCINFERENCESERVICE)

DESCRIPTOR.services_by_name['GRPCInferenceService'] = _GRPCINFERENCESERVICE

# @@protoc_insertion_point(module_scope)
