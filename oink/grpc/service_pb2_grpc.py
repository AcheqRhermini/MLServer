# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
import grpc

import service_pb2 as service__pb2


class GRPCInferenceServiceStub(object):
    """
    Inference Server GRPC endpoints.

    """

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.ServerLive = channel.unary_unary(
                '/oink.inferenceserver.GRPCInferenceService/ServerLive',
                request_serializer=service__pb2.ServerLiveRequest.SerializeToString,
                response_deserializer=service__pb2.ServerLiveResponse.FromString,
                )
        self.ServerReady = channel.unary_unary(
                '/oink.inferenceserver.GRPCInferenceService/ServerReady',
                request_serializer=service__pb2.ServerReadyRequest.SerializeToString,
                response_deserializer=service__pb2.ServerReadyResponse.FromString,
                )
        self.ModelReady = channel.unary_unary(
                '/oink.inferenceserver.GRPCInferenceService/ModelReady',
                request_serializer=service__pb2.ModelReadyRequest.SerializeToString,
                response_deserializer=service__pb2.ModelReadyResponse.FromString,
                )
        self.ServerMetadata = channel.unary_unary(
                '/oink.inferenceserver.GRPCInferenceService/ServerMetadata',
                request_serializer=service__pb2.ServerMetadataRequest.SerializeToString,
                response_deserializer=service__pb2.ServerMetadataResponse.FromString,
                )
        self.ModelMetadata = channel.unary_unary(
                '/oink.inferenceserver.GRPCInferenceService/ModelMetadata',
                request_serializer=service__pb2.ModelMetadataRequest.SerializeToString,
                response_deserializer=service__pb2.ModelMetadataResponse.FromString,
                )
        self.ModelInfer = channel.unary_unary(
                '/oink.inferenceserver.GRPCInferenceService/ModelInfer',
                request_serializer=service__pb2.ModelInferRequest.SerializeToString,
                response_deserializer=service__pb2.ModelInferResponse.FromString,
                )


class GRPCInferenceServiceServicer(object):
    """
    Inference Server GRPC endpoints.

    """

    def ServerLive(self, request, context):
        """Check liveness of the inference server.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def ServerReady(self, request, context):
        """Check readiness of the inference server.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def ModelReady(self, request, context):
        """Check readiness of a model in the inference server.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def ServerMetadata(self, request, context):
        """Get server metadata.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def ModelMetadata(self, request, context):
        """Get model metadata.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def ModelInfer(self, request, context):
        """Perform inference using a specific model.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_GRPCInferenceServiceServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'ServerLive': grpc.unary_unary_rpc_method_handler(
                    servicer.ServerLive,
                    request_deserializer=service__pb2.ServerLiveRequest.FromString,
                    response_serializer=service__pb2.ServerLiveResponse.SerializeToString,
            ),
            'ServerReady': grpc.unary_unary_rpc_method_handler(
                    servicer.ServerReady,
                    request_deserializer=service__pb2.ServerReadyRequest.FromString,
                    response_serializer=service__pb2.ServerReadyResponse.SerializeToString,
            ),
            'ModelReady': grpc.unary_unary_rpc_method_handler(
                    servicer.ModelReady,
                    request_deserializer=service__pb2.ModelReadyRequest.FromString,
                    response_serializer=service__pb2.ModelReadyResponse.SerializeToString,
            ),
            'ServerMetadata': grpc.unary_unary_rpc_method_handler(
                    servicer.ServerMetadata,
                    request_deserializer=service__pb2.ServerMetadataRequest.FromString,
                    response_serializer=service__pb2.ServerMetadataResponse.SerializeToString,
            ),
            'ModelMetadata': grpc.unary_unary_rpc_method_handler(
                    servicer.ModelMetadata,
                    request_deserializer=service__pb2.ModelMetadataRequest.FromString,
                    response_serializer=service__pb2.ModelMetadataResponse.SerializeToString,
            ),
            'ModelInfer': grpc.unary_unary_rpc_method_handler(
                    servicer.ModelInfer,
                    request_deserializer=service__pb2.ModelInferRequest.FromString,
                    response_serializer=service__pb2.ModelInferResponse.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'oink.inferenceserver.GRPCInferenceService', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))


 # This class is part of an EXPERIMENTAL API.
class GRPCInferenceService(object):
    """
    Inference Server GRPC endpoints.

    """

    @staticmethod
    def ServerLive(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/oink.inferenceserver.GRPCInferenceService/ServerLive',
            service__pb2.ServerLiveRequest.SerializeToString,
            service__pb2.ServerLiveResponse.FromString,
            options, channel_credentials,
            call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def ServerReady(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/oink.inferenceserver.GRPCInferenceService/ServerReady',
            service__pb2.ServerReadyRequest.SerializeToString,
            service__pb2.ServerReadyResponse.FromString,
            options, channel_credentials,
            call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def ModelReady(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/oink.inferenceserver.GRPCInferenceService/ModelReady',
            service__pb2.ModelReadyRequest.SerializeToString,
            service__pb2.ModelReadyResponse.FromString,
            options, channel_credentials,
            call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def ServerMetadata(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/oink.inferenceserver.GRPCInferenceService/ServerMetadata',
            service__pb2.ServerMetadataRequest.SerializeToString,
            service__pb2.ServerMetadataResponse.FromString,
            options, channel_credentials,
            call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def ModelMetadata(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/oink.inferenceserver.GRPCInferenceService/ModelMetadata',
            service__pb2.ModelMetadataRequest.SerializeToString,
            service__pb2.ModelMetadataResponse.FromString,
            options, channel_credentials,
            call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def ModelInfer(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/oink.inferenceserver.GRPCInferenceService/ModelInfer',
            service__pb2.ModelInferRequest.SerializeToString,
            service__pb2.ModelInferResponse.FromString,
            options, channel_credentials,
            call_credentials, compression, wait_for_ready, timeout, metadata)
